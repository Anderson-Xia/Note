```
import requests
import re
import pandas as pd
from pandas import DataFrame
from bs4 import BeautifulSoup
dic1 = {'cve': [],
        'url': [],
        'description': []
       }
NVD = 'nvd.nist.gov'
s_url = 'https://nvd.nist.gov/vuln/search/results?isCpeNameSearch=false&query=race&results_type=overview&form_type=Basic&search_type=all&startIndex='
i = 0
with open("cve.csv", "a+") as f:
    while 1:
        url = "https://nvd.nist.gov/vuln/search/results?isCpeNameSearch=false&query=race&results_type=overview&form_type=Basic&search_type=all&startIndex="+str(i)
        i += 20
        result = requests.get(url)
        content = result.content
        soup = BeautifulSoup(content,'lxml')
        vuls = soup.find_all(id='row')[0]
        table = vuls.find_all('table')[0].find_all('tbody')[0].find_all('tr')
        if len(table) == 0:
            break
        for vul in table:
            _id = vul.find_all(name='a', href=True)
            for href in _id:
                cur_url = href['href']
                cur_cve = href.string
                try:
                    if int(cur_cve.split('-')[1]) > 2013:
                        dic1['cve'].append(cur_cve)
                        dic1['url'].append(cur_url)
                        for des in vul.find_all(name='p'):
                            dic1['description'].append(des.string)
                except IndexError:
                    continue
            pass
df = pd.DataFrame(dic1)
df.to_excel('1.xlsx', index=False)
```